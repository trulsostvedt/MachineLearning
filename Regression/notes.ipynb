{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "133027b5",
   "metadata": {},
   "source": [
    "## Notes to the report (not part of delivery)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b16d33",
   "metadata": {},
   "source": [
    "Jeg forsøkte først kun én modell, koden til denne finnes under. \n",
    "\n",
    "Som jeg har kommentert i koden så prøvde jeg først polynomgrad 2–6, 4 og 5 ga nesten likt resultat på CV R^2 (0.93 ish), så 4 er nok bedre da den er lavere risiko for overfitting, og bruker heller det i det mymodel, men verdt å kommentere i rapporten for å vise refleksjon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9679cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_regression.py\n",
    "# -------------------\n",
    "# 1) Leser treningsdata\n",
    "# 2) Gjør modellvalg med GridSearchCV (PolynomialFeatures + StandardScaler + Ridge)\n",
    "# 3) Trener beste modell på hele datasettet\n",
    "# 4) Lagrer modellen (best_model.pkl) + en liten JSON med beste hyperparametre\n",
    "\n",
    "import json, joblib, numpy as np\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "import os\n",
    "print(\"Current working directory:\", os.getcwd())\n",
    "\n",
    "\n",
    "# Data \n",
    "base = Path(__file__).resolve().parent  # path to this script\n",
    "X = np.load(base / \"X_train.npy\")   # shape (700, 6)\n",
    "y = np.load(base / \"Y_train.npy\")   # shape (700,)\n",
    "\n",
    "# Pipeline og hyperparametre \n",
    "pipe = Pipeline([\n",
    "    (\"poly\",   PolynomialFeatures(include_bias=False)),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"ridge\",  Ridge())\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"poly__degree\": [2, 3, 4], #[2, 3, 4, 5, 6],  prøvde polynomgrad 2–6, både 4 og 5 ga nesten likt resultat på CV R^2, så 4 er nok bedre da den er lavere risiko for overfitting\n",
    "    \"ridge__alpha\": [1e-4 ,1e-3, 1e-2, 1e-1, 1, 10, 100, 1000, 10000],  # regulariseringsstyrke\n",
    "}\n",
    "\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "gs = GridSearchCV(pipe, param_grid, cv=cv, scoring=\"r2\", refit=True, n_jobs=-1)\n",
    "\n",
    "print(\"Running GridSearchCV...\")\n",
    "gs.fit(X, y)\n",
    "print(\"Best params:\", gs.best_params_, \" | CV R^2:\", gs.best_score_)\n",
    "\n",
    "# Trener beste modell på hele datasettet ---\n",
    "best_model = gs.best_estimator_\n",
    "best_model.fit(X, y)\n",
    "p\n",
    "# Lagrer modell og metadata ---\n",
    "joblib.dump(best_model, base / \"best_model.pkl\")\n",
    "with open(base / \"best_model_info.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"best_params\": gs.best_params_,\n",
    "        \"best_cv_r2\": gs.best_score_,\n",
    "        \"model_family\": \"PolynomialFeatures + StandardScaler + Ridge\"\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(\"Lagret: best_model.pkl og best_model_info.json\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bfeac",
   "metadata": {},
   "source": [
    "Videre la jeg til to andre modeller, og sammenlignet. Den nye koden tar nå å sjekker de 3 modellene opp mot hverandre, og lagrer den beste til best_model.pkl. Som videre loades av mymodel.py. Ny kode finnes under: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
